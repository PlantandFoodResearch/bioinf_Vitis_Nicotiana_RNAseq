{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>RNA-Seq Analysis Phase I: Quality Control\n",
    "## <i>This Notebook Performs QC on Paired-End RNA-Seq Data</i>\n",
    "#### Last Revision: July  2017\n",
    "#### Author: Charles David and Dan Jones\n",
    "#### This analysis done by Dan Jones and Karmun Chooi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Raw Data files are located on PowerPlant in the following location:\n",
    "\n",
    "\n",
    "```\n",
    "/input/genomic/viral/metagenomic/170621_150PE_HS4K2A/Almeida\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 57503130\n",
      "4437818 RACP005_11_S11_L002_R1_001.fastq.gz\n",
      "5087946 RACP005_11_S11_L002_R2_001.fastq.gz\n",
      "3832426 RACP005_12_S12_L002_R1_001.fastq.gz\n",
      "4360034 RACP005_12_S12_L002_R2_001.fastq.gz\n",
      "5640426 RACP005_13_S13_L002_R1_001.fastq.gz\n",
      "6387466 RACP005_13_S13_L002_R2_001.fastq.gz\n",
      "4137362 RACP005_1_S8_L002_R1_001.fastq.gz\n",
      "4970210 RACP005_1_S8_L002_R2_001.fastq.gz\n",
      "5553850 RACP005_5_S9_L002_R1_001.fastq.gz\n",
      "6399450 RACP005_5_S9_L002_R2_001.fastq.gz\n",
      "3088722 RACP005_8_S10_L002_R1_001.fastq.gz\n",
      "3607426 RACP005_8_S10_L002_R2_001.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECK\n",
    "ls -s /input/genomic/viral/metagenomic/170621_150PE_HS4K2A/Almeida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 170621_150PE_HS4K2A\n",
      "\n",
      "scientist:Arnaud Blouin\n",
      "\n",
      "downloaded:Ben Warren Thu Aug 31 16:40:30 NZST 2017\n",
      "\n",
      "type:RNAseq\n",
      "\n",
      "tech:150PE HiSeq4000 (minimum 2% PhiX control run on all libraries, up to 25% for diversity)\n",
      "\n",
      "organism:Vitis vinifera\n",
      "\n",
      "organism:Nicotiana benthamiana\n",
      "\n",
      "organism:GLRaV-3 (Grapevine leafroll-associated virus 3)\n",
      "\n",
      "description:RNA from hosts infected with virus\n",
      "\n",
      "samples:Almeida, Christensen, Martin, Nagalingum, Taylor\n",
      "\n",
      "notes:\n",
      "\n",
      " - Lane 1 Matthew Niemiller & Taylor Lab\n",
      " - Lane 2 Cecilia & Prator Lab\n",
      " - Lane 3 Alan Christensen Lab\n",
      " - Lane 4 Nathalie Nagalingum/James Clugston &  Cal Academy\n",
      " - Lane 5-8 Christopher Martin Lab\n",
      "\n",
      "\n",
      "150PE HiSeq4000 (minimum 2% PhiX control run on all libraries, up to 25% for diversity)\n",
      "\n",
      " - 1 BPO, 3nM, INDEX (426M Reads, 9.4% PhiX Aligned)\n",
      " - 2 RACO005, 3nM, INDEX (396M Reads, 3.0% PhiX Aligned)\n",
      " - 3 ACK101, 3nM, INDEX (390M Reads, 4.7% PhiX Aligned)\n",
      " - 4 Cycas4, 3nM, INDEX (397M Reads, 5.2% PhiX Aligned)\n",
      " - 5 CHM-CustomPool, 3nM, INDEX (382M Reads, 3.3% PhiX Aligned)\n",
      " - 6 CMNC_1, 3nM, INDEX (382M Reads, 3.3% PhiX Aligned)\n",
      " - 7 CMNC_2, 3nM, INDEX (378M Reads, 2.8% PhiX Aligned) \n",
      " - 8 CMNC_3, 3nM, INDEX (388M Reads, 2.8% PhiX Aligned)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SANITY CHECK: What does the README.md file say?\n",
    "cat /input/genomic/viral/metagenomic/170621_150PE_HS4K2A/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>The key steps are: </u>##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. Establish Data Management Structure on PowerPlant\n",
    "1. Make the necessary directories for the data and the analysis\n",
    "2. Name the directories using standard workflow naming conventions\n",
    "3. Name files using standard workflow naming conventions\n",
    "4. Make README.md files when needed\n",
    "\n",
    "#### II. Perform the analyses\n",
    "1. FastQC RAW Data\n",
    "2. SortMeRNA\n",
    "3. FastQC SortMeRNA Output\n",
    "4. Trimmomatic\n",
    "5. FastQC Trimmomatic Output\n",
    "6. Clean Up Workspace:\n",
    "     - Delete un-needed intermediate files\n",
    "     - Compress files that are still required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step I: Establish Data Management Structure on PowerPlant</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Project Variables\n",
    "\n",
    "* We define my Plant and Food Research (PFR) username as a variable: `USER`\n",
    "* We define a unique project name as a variable: `PROJECTNAME`\n",
    "* By combining these variables, we create a new variable that defines a directory within my workspace where all outputs will be placed: `PROJECT`\n",
    "* We also create a number of variables that refer to specific subdirectories within `PROJECT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the user as a variable\n",
    "USER=\"hradxj\"\n",
    "PROJECTNAME=\"karmun_awesome_experiment\"\n",
    "# Define the project directory and temp subdirectory as a variable\n",
    "PROJECT=\"/workspace/$USER/$PROJECTNAME\"\n",
    "\n",
    "# Define the location of various subdirectories within PROJECT\n",
    "\n",
    "RAW=$PROJECT/000.raw\n",
    "FASTQC_RAW=$PROJECT/001.fastqc_raw\n",
    "SORTMERNA=$PROJECT/002.SMRNA\n",
    "FASTQC_SORTMERNA=$PROJECT/003.fastqc_smrna\n",
    "TRIMMOMATIC=$PROJECT/004.trimmomatic\n",
    "FASTQC_TRIMMOMATIC=$PROJECT/005.fastqc_trim\n",
    "TEMP=\"$PROJECT/TEMP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create analysis directories\n",
    "\n",
    "At this point, we have not actually created any directories... only defined what the directory is going to be called __when__ we create it. We still need to actually create the directories.\n",
    "\n",
    "We use the Unix shell command `mkdir` to create the directories. The switch `-p` suppresses error messages if the directory already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the project directory\n",
    "\n",
    "mkdir -p $PROJECT\n",
    "\n",
    "# Create project subdirectories\n",
    "\n",
    "mkdir -p $RAW\n",
    "mkdir -p $FASTQC_RAW\n",
    "mkdir -p $SORTMERNA\n",
    "mkdir -p $FASTQC_SORTMERNA\n",
    "mkdir -p $TRIMMOMATIC\n",
    "mkdir -p $FASTQC_TRIMMOMATIC\n",
    "mkdir -p $TEMP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SANITY CHECK\n",
    "Have the project directory and subdirectories been created correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000.raw\t\t003.fastqc_smrna  006.MIA   009.STAR\t  Illumina.fa\n",
      "001.fastqc_raw\t004.trimmomatic   007.STAR  010.edgeR_Nb  log\n",
      "002.SMRNA\t005.fastqc_trim   008.MBA   011.edgeR_Vv  TEMP\n"
     ]
    }
   ],
   "source": [
    "ls $PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the project directory exists and has the appropriate subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create symlinks of all input fastq files and put them in $RAW\n",
    "\n",
    "ln -s /input/genomic/viral/metagenomic/170621_150PE_HS4K2A/Almeida/*.fastq.gz $RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check: does the raw directory exist, and what is in it?\n",
      "total 18\n",
      "2 RACP005_11_S11_L002_R1_001.fastq.gz  2 RACP005_1_S8_L002_R1_001.fastq.gz\n",
      "2 RACP005_11_S11_L002_R2_001.fastq.gz  2 RACP005_1_S8_L002_R2_001.fastq.gz\n",
      "2 RACP005_12_S12_L002_R1_001.fastq.gz  2 RACP005_5_S9_L002_R1_001.fastq.gz\n",
      "2 RACP005_12_S12_L002_R2_001.fastq.gz  2 RACP005_5_S9_L002_R2_001.fastq.gz\n",
      "2 RACP005_13_S13_L002_R1_001.fastq.gz  2 RACP005_8_S10_L002_R1_001.fastq.gz\n",
      "2 RACP005_13_S13_L002_R2_001.fastq.gz  2 RACP005_8_S10_L002_R2_001.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: does the raw directory exist, and what is in it?\n",
    "echo \"Sanity check: does the raw directory exist, and what is in it?\"\n",
    "ls -s $RAW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change filenames\n",
    "FILENAMES=$(ls $RAW)\n",
    "#echo $FILENAMES\n",
    "for FILE in $FILENAMES\n",
    "do\n",
    "NEWFILENAME=$(echo $FILE | sed 's/_001//g')\n",
    "mv $RAW/$FILE $RAW/$NEWFILENAME\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 18\n",
      "2 RACP005_11_S11_L002_R1.fastq.gz  2 RACP005_1_S8_L002_R1.fastq.gz\n",
      "2 RACP005_11_S11_L002_R2.fastq.gz  2 RACP005_1_S8_L002_R2.fastq.gz\n",
      "2 RACP005_12_S12_L002_R1.fastq.gz  2 RACP005_5_S9_L002_R1.fastq.gz\n",
      "2 RACP005_12_S12_L002_R2.fastq.gz  2 RACP005_5_S9_L002_R2.fastq.gz\n",
      "2 RACP005_13_S13_L002_R1.fastq.gz  2 RACP005_8_S10_L002_R1.fastq.gz\n",
      "2 RACP005_13_S13_L002_R2.fastq.gz  2 RACP005_8_S10_L002_R2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "ls -s $RAW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step II Part 1: FastQC RAW Data</u>\n",
    "- The input for this step is the raw data from the provider in FASTQ format\n",
    "- The output from this step are the HTML FASTQC Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the location for the QC reports:\n",
    "OUT=\"${PROJECT}/001.fastqc_raw\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "\n",
    "mkdir -p $LOG\n",
    "\n",
    "# Define the list of files to process:\n",
    "FILES=`ls ${RAW}/*.gz`\n",
    "\n",
    "# Load the FastQC module:\n",
    "module load FastQC\n",
    "\n",
    "for file in $FILES\n",
    "    do\n",
    "        COMMAND=\"fastqc --nogroup -q -t 2 -o ${OUT} ${file}\"\n",
    "        bsub -o ${LOG}/FQC.out -e ${LOG}/FQC.err -J FASTQC -n 2 $COMMAND\n",
    "    done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID   USER    STAT  QUEUE      FROM_HOST   EXEC_HOST   JOB_NAME   SUBMIT_TIME\n",
      "596445  hradxj  RUN   normal     aklppr31    wkoppb37    MERGE      Nov  8 09:21\n",
      "596447  hradxj  RUN   normal     aklppr31    wkoppb37    MERGE      Nov  8 09:21\n",
      "596448  hradxj  RUN   normal     aklppr31    wkoppb37    MERGE      Nov  8 09:21\n",
      "596450  hradxj  RUN   normal     aklppr31    wkoppb37    MERGE      Nov  8 09:21\n",
      "596451  hradxj  RUN   normal     aklppr31    wkoppb37    MERGE      Nov  8 09:21\n",
      "596452  hradxj  RUN   normal     aklppr31    wkoppb37    MERGE      Nov  8 09:21\n",
      "596490  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596491  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596492  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596493  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596494  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596495  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596496  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596497  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596498  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596499  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596500  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n",
      "596501  hradxj  RUN   normal     aklppr31    wkoppb35    FASTQC     Nov  8 09:52\n",
      "                                             wkoppb35\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Have we produced the FASTQC reports?\n",
    "# If you run this cell, you should see a set of \".html\" and \".zip\" files.\n",
    "# You can view the reports by opening a web browser and looking at:\n",
    "# http://storage.powerplant.pfr.co.nz/workspace/hrhsxj/vpnhr/001.\n",
    "bjobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict with existing python virtual environment. Please run `deactivate` to unload MultiQC-1.2\n",
      "[WARNING]         multiqc : MultiQC Version v1.3 now available!\n",
      "[INFO   ]         multiqc : This is MultiQC v1.2\n",
      "[INFO   ]         multiqc : Template    : default\n",
      "[INFO   ]         multiqc : Searching '/workspace/hradxj/karmun_awesome_experiment/001.fastqc_raw'\n",
      "\u001b[?25lSearching 26 files..  [####################################]  100%\u001b[?25h\n",
      "[INFO   ]          fastqc : Found 12 reports\n",
      "[INFO   ]         multiqc : Compressing plot data\n",
      "[INFO   ]         multiqc : Report      : ../../../../workspace/hradxj/karmun_awesome_experiment/001.fastqc_raw/multiqc_report.html\n",
      "[INFO   ]         multiqc : Data        : ../../../../workspace/hradxj/karmun_awesome_experiment/001.fastqc_raw/multiqc_data\n",
      "[INFO   ]         multiqc : MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "# Create multiQC report of FastQC results\n",
    "module load MultiQC;\n",
    "multiqc $OUT -o $OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://storage.powerplant.pfr.co.nz/workspace/hradxj/karmun_awesome_experiment/001.fastqc_raw/multiqc_report.html\n"
     ]
    }
   ],
   "source": [
    "echo \"http://storage.powerplant.pfr.co.nz/workspace/hradxj/karmun_awesome_experiment/001.fastqc_raw/multiqc_report.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "* Put your own notes here about what the FASTQC results look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step II Part 2: SortMeRNA</u>\n",
    "* In this step we will remove any rRNA contamination by comparing our reads to 6 databases of known rRNA's\n",
    "* We will capture the rRNA reads in case further investigation is needed\n",
    "* We will output the filtered reads to use for our workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge (interleave) paired fastq files\n",
    "* The input to this step is the raw data in FASTQ format\n",
    "\n",
    "__NOTE THAT THIS WILL WORK ONLY IF PAIRED FILES END IN \"_R1.fastq.gz\" and \"_R2.fastq.gz\"__\n",
    "\n",
    "* SortMeRNA requires that paired-end files are merged (intereaved) prior to execution\n",
    "* There is a Bash shell script that does this called `merge-paired-reads.sh` in the `/scripts` subdirectory\n",
    "* NOTE! This script can NOT process zipped files!!!\n",
    "  * Therefore, all files must be de-compressed prior to use...\n",
    "  * This is best done with process substitution, using `<(zcat ...)`\n",
    "* The output from this step are interleaved fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/hradxj/karmun_awesome_experiment\n"
     ]
    }
   ],
   "source": [
    "# Define the location of the various QC programs we will be using,\n",
    "# and the location of SortMeRNA rRNA databases\n",
    "\n",
    "SMRNA=\"/workspace/cflcyd/software/sortmerna-2.1b\"\n",
    "SCRIPTS=\"${SMRNA}/scripts\"\n",
    "DB=\"${SMRNA}/rRNA_databases\"\n",
    "INDEX=\"${SMRNA}/index\"\n",
    "SORTMERNADB=\"${DB}/silva-bac-16s-id90.fasta,\\\n",
    "${INDEX}/silva-bac-16s-db:\\\n",
    "${DB}/silva-bac-23s-id98.fasta,\\\n",
    "${INDEX}/silva-bac-23s-db:\\\n",
    "${DB}/silva-arc-16s-id95.fasta,\\\n",
    "${INDEX}/silva-arc-16s-db:\\\n",
    "${DB}/silva-arc-23s-id98.fasta,\\\n",
    "${INDEX}/silva-arc-23s-db:\\\n",
    "${DB}/silva-euk-18s-id95.fasta,\\\n",
    "${INDEX}/silva-euk-18s-db:\\\n",
    "${DB}/silva-euk-28s-id98.fasta,\\\n",
    "${INDEX}/silva-euk-28s:\\\n",
    "${DB}/rfam-5s-database-id98.fasta,\\\n",
    "${INDEX}/rfam-5s-db:\\\n",
    "${DB}/rfam-5.8s-database-id98.fasta,\\\n",
    "${INDEX}/rfam-5.8s-db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RACP005_11_S11_L002_R1.fastq.gz\n",
      "RACP005_11_S11_L002_R2.fastq.gz\n",
      "RACP005_12_S12_L002_R1.fastq.gz\n",
      "RACP005_12_S12_L002_R2.fastq.gz\n",
      "RACP005_13_S13_L002_R1.fastq.gz\n",
      "RACP005_13_S13_L002_R2.fastq.gz\n",
      "RACP005_1_S8_L002_R1.fastq.gz\n",
      "RACP005_1_S8_L002_R2.fastq.gz\n",
      "RACP005_5_S9_L002_R1.fastq.gz\n",
      "RACP005_5_S9_L002_R2.fastq.gz\n",
      "RACP005_8_S10_L002_R1.fastq.gz\n",
      "RACP005_8_S10_L002_R2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Do the paired input files end in \"_R1.fastq.gz\" and \"_R2.fastq.gz\"?\n",
    "# If the following command does not result in the full list\n",
    "# of the name of your input files (without directories), STOP, since there is a problem.\n",
    "basename --multiple $RAW/* | grep '_R1.fastq.gz\\|_R2.fastq.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the location for the merged files:\n",
    "OUT=\"${PROJECT}/002.SMRNA\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "\n",
    "# Define a set of unique names of the paired files,\n",
    "# but excluding the _R1.fastq.gz and _R2.fastq.gz.\n",
    "# This means that the variable \"FILES\" will consist of a unique name\n",
    "# for each PAIR of paired fastq files. We can then append the \n",
    "# _R1.fastq.gz and _R2.fastq.gz suffix within the loop, to ensure\n",
    "# that each iteration of the loop is working on two correctly paired files.\n",
    "\n",
    "FILES=`basename -a ${RAW}/*.gz | sed 's/_R[1,2].fastq.gz//g'|sort -u `\n",
    "\n",
    "for file in $FILES\n",
    "     do\n",
    "\n",
    "        file1=${file}_R1.fastq.gz\n",
    "        file2=${file}_R2.fastq.gz\n",
    "        COMMAND=\"${SCRIPTS}/Merge.sh \\\n",
    "                <(zcat $RAW/${file1}) \\\n",
    "                <(zcat $RAW/${file2}) \\\n",
    "                ${OUT}/${file}_MERGED.fastq\"\n",
    "        #echo \"$COMMAND\"\n",
    "        bsub -o ${LOG}/MERGE.out -e ${LOG}/MERGE.err -J MERGE bash -c \"${COMMAND}\"\n",
    "     done\n",
    "\n",
    "### Note that the bash -c is needed to open a proper bash shell\n",
    "### (instead of a bourne shell) for the processes substitution to work with OpenLava ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 301062105\n",
      "49333114 RACP005_11_S11_L002_MERGED.fastq\n",
      "39056434 RACP005_12_S12_L002_MERGED.fastq\n",
      "57527458 RACP005_13_S13_L002_MERGED.fastq\n",
      "54648034 RACP005_1_S8_L002_MERGED.fastq\n",
      "55260978 RACP005_5_S9_L002_MERGED.fastq\n",
      "45236090 RACP005_8_S10_L002_MERGED.fastq\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Have we actually produced the interleaved FASTQ files for use in SortMeRNA?\n",
    "# You should see a file called <yourfile>_MERGED.fastq for every PAIR of reads in your \n",
    "# input data.If the process is still running, you should see files called \n",
    "# <yourfile>__MERGED.fastq.READS1 and <yourfile>__MERGED.fastq.READS2. \n",
    "# Do not proceed to the next step until you ONLY see files called <yourfile>_MERGED.fastq\n",
    "# Note that this merging step can take several hours!\n",
    "ls -s $OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Main SortMeRNA Program\n",
    "* This is what actually does the sorting\n",
    "* The input to this step are the merged fastq files\n",
    "* The output are the rRNA matches and the filtered raw reads in interleaved fastq format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <620803> is submitted to default queue <normal>.\n",
      "Job <620804> is submitted to default queue <normal>.\n",
      "Job <620805> is submitted to default queue <normal>.\n",
      "Job <620806> is submitted to default queue <normal>.\n",
      "Job <620807> is submitted to default queue <normal>.\n",
      "Job <620808> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "# Define the location for the input and output files:\n",
    "IN=\"${PROJECT}/002.SMRNA\"\n",
    "OUT=\"${PROJECT}/002.SMRNA\"\n",
    "FILTERED=\"${OUT}/filtered/merged\"\n",
    "rRNA=\"${OUT}/rRNA\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "\n",
    "mkdir -p $rRNA\n",
    "mkdir -p $LOG\n",
    "mkdir -p $FILTERED\n",
    "\n",
    "### module load sortmerna ### Not until latest version is installed and configured...\n",
    "\n",
    "FILES=`ls ${IN}/*_MERGED.fastq`\n",
    "\n",
    "for file in $FILES\n",
    "    do\n",
    "        NAME=`basename $file`\n",
    "        COMMAND=\"${SMRNA}/sortmerna --ref ${SORTMERNADB} --reads ${file} \\\n",
    "                --paired_in -a 4 -m 3911 -v --log --fastx \\\n",
    "                --aligned ${rRNA}/${NAME}_rRNA \\\n",
    "                --other ${FILTERED}/${NAME}_sortmerna\"\n",
    "        bsub -o ${LOG}/${NAME}.out -e ${LOG}/${NAME}.err -J SMRNA -n 4 $COMMAND\n",
    "     done\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Results:\n",
    "    Total reads = 26,184,138\n",
    "    Total reads passing E-value threshold = 225,953 (0.86%)\n",
    "    Total reads failing E-value threshold = 25,958,185 (99.14%)\n",
    "    Minimum read length = 100\n",
    "    Maximum read length = 100\n",
    "    Mean read length = 100\n",
    " By database:\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/silva-bac-16s-id90.fasta\t\t    0.20%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/silva-bac-23s-id98.fasta\t\t    0.07%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/silva-arc-16s-id95.fasta\t\t    0.00%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/silva-arc-23s-id98.fasta\t\t    0.00%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/silva-euk-18s-id95.fasta\t\t    0.34%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/silva-euk-28s-id98.fasta\t\t    0.25%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/rfam-5s-database-id98.fasta\t\t0.00%\n",
    "    /workspace/cflcyd/software/sortmerna-2.1b/rRNA_databases/rfam-5.8s-database-id98.fasta\t\t0.00%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un-merge (de-interleave) the filtered fastq files\n",
    "* The other programs in our workflow use standard non-interleaved files, so we unmerge them.\n",
    "* The input is the merged fastq files\n",
    "* The output are the unmerged fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <631684> is submitted to default queue <normal>.\n",
      "Job <631685> is submitted to default queue <normal>.\n",
      "Job <631686> is submitted to default queue <normal>.\n",
      "Job <631687> is submitted to default queue <normal>.\n",
      "Job <631688> is submitted to default queue <normal>.\n",
      "Job <631689> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "IN=\"${PROJECT}/002.SMRNA/filtered/merged\"\n",
    "OUT=\"${PROJECT}/002.SMRNA/filtered\"\n",
    "\n",
    "FILENAMES=`ls ${IN}/*sortmerna*`\n",
    "\n",
    "for file in $FILENAMES\n",
    "     do\n",
    "        # echo $file\n",
    "        NAME=`basename $file`\n",
    "        PREFIX=`echo $NAME | awk -F'[. ]' '{print $1}'`\n",
    "        #echo $PREFIX\n",
    "        file1=${OUT}/${PREFIX}_R1.fastq\n",
    "        file2=${OUT}/${PREFIX}_R2.fastq\n",
    "        COMMAND=\"${SCRIPTS}/Unmerge.sh $file $file1 $file2\"\n",
    "       # echo $COMMAND\n",
    "        bsub -J UNMERGE -n 3 ${COMMAND}\n",
    "     done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove merged files\n",
    "rm -rf ${PROJECT}/002.SMRNA/filtered/merged/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step II Part 3: FastQC SortMeRNA Filtered Output</u>\n",
    "* We now verify that we did not break anything and re-check the quality of our reads after sorting\n",
    "* The input for this step is the filtered data from SortMeRNA in FASTQ format\n",
    "* The output from this step are the HTML FastQC Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <634263> is submitted to default queue <normal>.\n",
      "Job <634264> is submitted to default queue <normal>.\n",
      "Job <634265> is submitted to default queue <normal>.\n",
      "Job <634266> is submitted to default queue <normal>.\n",
      "Job <634267> is submitted to default queue <normal>.\n",
      "Job <634268> is submitted to default queue <normal>.\n",
      "Job <634269> is submitted to default queue <normal>.\n",
      "Job <634270> is submitted to default queue <normal>.\n",
      "Job <634271> is submitted to default queue <normal>.\n",
      "Job <634272> is submitted to default queue <normal>.\n",
      "Job <634273> is submitted to default queue <normal>.\n",
      "Job <634274> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "IN=\"${PROJECT}/002.SMRNA/filtered\"\n",
    "OUT=\"${PROJECT}/003.fastqc_smrna\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "\n",
    "# Get the files to check:\n",
    "FILES=`ls ${IN}/*.fastq`\n",
    "#echo $FILES\n",
    "\n",
    "# Load the FastQC module:\n",
    "module load FastQC\n",
    "\n",
    "for file in $FILES\n",
    "    do\n",
    "        COMMAND=\"fastqc --nogroup -q -t 2 -o ${OUT} ${file}\"\n",
    "        bsub -o ${LOG}/FQC.out -e ${LOG}/FQC.err -J FASTQC -n 2 $COMMAND\n",
    "    done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING]         multiqc : MultiQC Version v1.3 now available!\n",
      "[INFO   ]         multiqc : This is MultiQC v1.2\n",
      "[INFO   ]         multiqc : Template    : default\n",
      "[INFO   ]         multiqc : Searching '/workspace/hradxj/karmun_awesome_experiment/002.SMRNA'\n",
      "\u001b[?25lSearching 18 files..  [####################################]  100%\u001b[?25h\n",
      "[WARNING]         multiqc : No analysis results found. Cleaning up..\n",
      "[INFO   ]         multiqc : MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "# Create multiQC report of FastQC results\n",
    "module load MultiQC;\n",
    "multiqc $OUT -o $OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://storage.powerplant.pfr.co.nz/workspace/hradxj/karmun_awesome_experiment/003.fastqc_smrna/multiqc_report.html\n"
     ]
    }
   ],
   "source": [
    "echo \"http://storage.powerplant.pfr.co.nz/workspace/hradxj/karmun_awesome_experiment/003.fastqc_smrna/multiqc_report.html\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "* Check for the level of contaimination: < 2% is great. Not more than 10% is OK, but should be noted.\n",
    "* You will see that the total nuber of reades in each file is now slightly less due to the filtering\n",
    "* Many issues still remain: Over-represented sequences, Adapter removal, Quality trimming\n",
    "  * These issues will be handled next by Trimmomatic and MarkIlluminaAdapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step II Part 4: TRIMMOMATIC</u>\n",
    "* Now that the reads are filtered, we will remove adapters, over-represented sequences, and poor-quality bases from the reads\n",
    "* The command specifies that bases with quality scores less than 30 will be clipped\n",
    "* Also, after clipping, the min length for a read will be 50 bp\n",
    "* The `Illumina.fa` file contains the TruSeq adapter sequences and homo-polymer sequences to clip\n",
    "  * This file needs to be edited to contain the appropriate sequences.\n",
    "* The input for this step are the SortMeRNA filtered reads\n",
    "* The output are the trimmed reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <635141> is submitted to default queue <normal>.\n",
      "Job <635142> is submitted to default queue <normal>.\n",
      "Job <635143> is submitted to default queue <normal>.\n",
      "Job <635144> is submitted to default queue <normal>.\n",
      "Job <635145> is submitted to default queue <normal>.\n",
      "Job <635146> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "# Run the Trimmomatic program on the filtered data to remove Illumina adapters, homo-polymers, and low quality reads:\n",
    "  # Note that to do this, it is necessary to edit the file containing the adapter sequences\n",
    "  # to include all sequences that you wish to remove:\n",
    "  # This file is called Illumina.fa and is in the 000.raw directory.\n",
    "\n",
    "IN=\"${PROJECT}/002.SMRNA/filtered\"\n",
    "OUT=\"${PROJECT}/004.trimmomatic\"\n",
    "UNPAIRED=\"${OUT}/unpaired\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "\n",
    "mkdir -p $IN\n",
    "mkdir -p $OUT\n",
    "mkdir -p $UNPAIRED\n",
    "mkdir -p $LOG\n",
    "\n",
    "# Set the path to the adapter file:\n",
    "CLIP=\"${PROJECT}/Illumina.fa\"\n",
    "\n",
    "# Get the files to trim:\n",
    "# Use echo statements to be sure that the results from awk are what you really want...\n",
    "FILES=`basename -a ${IN}/*.fastq | sed 's/_R[1,2].fastq//g'|sort -u `\n",
    "#FILES=`ls ${IN}/*.fastq | awk -F'[_ ]' '{print $1\"_\"$2\"_\"$3\"_\"$4\"_\"$5\"_\"$6}' | sort -u`\n",
    "\n",
    "#echo $FILES\n",
    "module load Trimmomatic\n",
    "\n",
    "for FILE in $FILES\n",
    "     do\n",
    "        In_File1=${IN}/${FILE}_R1.fastq\n",
    "        In_File2=${IN}/${FILE}_R2.fastq\n",
    "  #      echo $In_File1\n",
    "  #      echo $In_File2\n",
    "        Out_PAIRED_1=${OUT}/${FILE}_trimmomatic_R1.fastq\n",
    "        Out_UNPAIRED_1=${UNPAIRED}/${FILE}_trimmomatic_unpaired_1.fastq\n",
    "        Out_PAIRED_2=${OUT}/${FILE}_trimmomatic_R2.fastq\n",
    "        Out_UNPAIRED_2=${UNPAIRED}/${FILE}_trimmomatic_unpaired_2.fastq\n",
    "  #      echo $Out_PAIRED_1\n",
    "  #      echo $Out_UNPAIRED_1\n",
    "  #      echo $Out_PAIRED_2\n",
    "  #      echo $Out_UNPAIRED_2\n",
    "        COMMAND=\"java -jar -Xms8G -Xmx8G \\\n",
    "                 ${TRIMMOMATIC} PE -threads 3 \\\n",
    "                 ${In_File1} ${In_File2} \\\n",
    "                 ${Out_PAIRED_1} ${Out_UNPAIRED_1} ${Out_PAIRED_2} ${Out_UNPAIRED_2} \\\n",
    "                 ILLUMINACLIP:${CLIP}:2:30:10 SLIDINGWINDOW:5:20 MINLEN:50\"\n",
    "        #echo $COMMAND\n",
    "        bsub -o ${LOG}/${PREFIX}.out -e ${LOG}/${PREFIX}.err -J TRIM -n 3 $COMMAND\n",
    "     done\n",
    "\n",
    "# It is critical to set the -X settings for Java for the program to run correctly\n",
    "# Here, the VM is instantiated with 8GB of heap space, with a max of 8GB...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Summary:\n",
    "* ILLUMINACLIP: Using 1 prefix pairs, 8 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
    "* Quality encoding detected as phred33\n",
    "* Input Read Pairs: 12,928,498 \n",
    "* Both Surviving: 11,702,894 (90.52%) \n",
    "* Forward Only Surviving: 570,865 (4.42%) \n",
    "* Reverse Only Surviving: 181,229 (1.40%) \n",
    "* Dropped: 473,510 (3.66%)\n",
    "* So we have over 90% of reads passing our criteria!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step II Part 5: FASTQC of TRIMMED READS</u>\n",
    "* We now verify that we did not break anything and re-check the quality of our reads after trimming\n",
    "* The input for this step are the filtered trimmed reads in FASTQ format\n",
    "* The output from this step are the HTML Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <646929> is submitted to default queue <normal>.\n",
      "Job <646930> is submitted to default queue <normal>.\n",
      "Job <646931> is submitted to default queue <normal>.\n",
      "Job <646932> is submitted to default queue <normal>.\n",
      "Job <646933> is submitted to default queue <normal>.\n",
      "Job <646934> is submitted to default queue <normal>.\n",
      "Job <646935> is submitted to default queue <normal>.\n",
      "Job <646936> is submitted to default queue <normal>.\n",
      "Job <646937> is submitted to default queue <normal>.\n",
      "Job <646938> is submitted to default queue <normal>.\n",
      "Job <646939> is submitted to default queue <normal>.\n",
      "Job <646940> is submitted to default queue <normal>.\n"
     ]
    }
   ],
   "source": [
    "IN=\"${PROJECT}/004.trimmomatic\"\n",
    "OUT=\"${PROJECT}/005.fastqc_trim\"\n",
    "LOG=\"${OUT}/logs\"\n",
    "\n",
    "# Get the files to check:\n",
    "FILES=`ls ${IN}/*trimmomatic*`\n",
    "\n",
    "# Load the FastQC module:\n",
    "module load FastQC\n",
    "\n",
    "for file in $FILES\n",
    "    do\n",
    "        COMMAND=\"fastqc --nogroup -q -t 2 -o ${OUT} ${file}\"\n",
    "        bsub -o ${LOG}/FQC.out -e ${LOG}/FQC.err -J FASTQC -n 2 $COMMAND\n",
    "    done\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO   ]         multiqc : This is MultiQC v1.3\n",
      "[INFO   ]         multiqc : Template    : default\n",
      "[INFO   ]         multiqc : Searching '/workspace/hradxj/karmun_awesome_experiment/005.fastqc_trim'\n",
      "\u001b[?25lSearching 24 files..  [####################################]  100%\u001b[?25h\n",
      "[INFO   ]          fastqc : Found 12 reports\n",
      "[INFO   ]         multiqc : Compressing plot data\n",
      "[INFO   ]         multiqc : Report      : ../../../../workspace/hradxj/karmun_awesome_experiment/005.fastqc_trim/multiqc_report.html\n",
      "[INFO   ]         multiqc : Data        : ../../../../workspace/hradxj/karmun_awesome_experiment/005.fastqc_trim/multiqc_data\n",
      "[INFO   ]         multiqc : MultiQC complete\n"
     ]
    }
   ],
   "source": [
    "# Create multiQC report of FastQC results\n",
    "module load MultiQC;\n",
    "multiqc $OUT -o $OUT;\n",
    "module unload MultiQC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://storage.powerplant.pfr.co.nz/workspace/hradxj/karmun_awesome_experiment/005.fastqc_trim/multiqc_report.html\n"
     ]
    }
   ],
   "source": [
    "echo \"http://storage.powerplant.pfr.co.nz/workspace/hradxj/karmun_awesome_experiment/005.fastqc_trim/multiqc_report.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptor contamination in R1 reads. This was successfully removed, which you can see when comparing the pre- and post- trimmomatic MultiQC reports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Step III: Assess the transformed data for suitabillity in downstream analysis</u>\n",
    "* Here we need to assess the condition of our transformed reads for downstream analysis\n",
    "* Look at the FastQC Report for the trimmed data: Looks great.\n",
    "* Check for any obvious problems: No red flags.\n",
    "* Look at the metrics files from MIA to see what was found: A few more adapters were cliped...not bad.\n",
    "* Different standards apply depending on the type of downstream analysis: differential experession analysis or variant calling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This marks the end of the QC Pre-Processing of the RNA-Seq Data\n",
    "* The next step typically is to align to an available reference set:\n",
    "    * Genome\n",
    "        * `RNA_Seq_Analysis_Phase_IIa_Alignment_to_Reference_Genome_Revised_July_2017.ipynb`\n",
    "    * Transcriptome\n",
    "        * `RNA_Seq_Analysis_Phase_IIb_Alignment_to_Transcriptome.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
